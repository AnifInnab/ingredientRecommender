{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "* Stemming for all ingredients in recipes\n",
    "* Remove adjectives from ingredients in recipes\n",
    "    if this fails, use standardized ingredients from some website\n",
    "* Create techniques vector, write down 20 techniques and see if they are present in steps string\n",
    "* \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, LSTM, GRU\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "from functools import reduce\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285069acb94c415b92679ecbd3f6a112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Read files\n",
    "recipes_path = 'data/RAW_recipes.csv'\n",
    "orig_recipes = pd.read_csv(recipes_path)\n",
    "orig_recipes = orig_recipes['ingredients']\n",
    "orig_recipes = list(orig_recipes.apply(ast.literal_eval))\n",
    "\n",
    "ingredients_with_dup = []\n",
    "for recipe in orig_recipes:\n",
    "    ingredients_with_dup += recipe\n",
    "\n",
    "df = pd.Series(data=ingredients_with_dup)\n",
    "ingr_counts = df.value_counts()\n",
    "tot_sum = ingr_counts.sum()\n",
    "\n",
    "ingredients = list(ingr_counts[ingr_counts > 100].index)\n",
    "ingredients_set = set(ingredients)\n",
    "ingredients_dict = {ingr:i for i,ingr in tqdm(enumerate(ingredients))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231637\n",
      "118996\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e23c326f4b4a3d9b9417016b26b163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=118996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(118996, 34)\n",
      "(118996, 1826)\n"
     ]
    }
   ],
   "source": [
    "def recipe_to_idx(recipe):\n",
    "    return list(map(lambda x : ingredients_dict[x], recipe))\n",
    "\n",
    "def idx_to_recipe(idx_list):\n",
    "    return [ingredients[i] for i in idx_list]\n",
    "\n",
    "def filter_recipes(recipes):\n",
    "    \"\"\"\n",
    "    removes recipe if ingredients in recipe is not in our ingredients list\n",
    "    \"\"\"\n",
    "    filtered_recipes = []\n",
    "    for i, recipe in enumerate(recipes):\n",
    "        found = True\n",
    "        for word in recipe:\n",
    "            if word not in ingredients_set:\n",
    "                found = False\n",
    "                break\n",
    "        if found and len(recipe) > 0:\n",
    "            filtered_recipes.append(recipe)\n",
    "    return filtered_recipes\n",
    "\n",
    "def create_labels(recipes_indices):\n",
    "    \"\"\"\n",
    "    creates a list of labels, where each label is an index pointing to some ingredient in the ingredients list\n",
    "    \"\"\"\n",
    "    y_indices = []\n",
    "    for recipe in recipes_indices:\n",
    "        label_pos = random.randint(0, len(recipe) - 1)\n",
    "        y_indices.append(recipe[label_pos])\n",
    "        recipe.pop(label_pos)\n",
    "    return y_indices\n",
    "\n",
    "def pad_X(recipes_indices):\n",
    "    \"\"\"\n",
    "    Pads the index lists so that they all have the same size\n",
    "    \"\"\"\n",
    "    longest_recipe_size = max([len(recipe) for recipe in recipes_indices])\n",
    "    X = pad_sequences(recipes_indices, maxlen=longest_recipe_size, padding='post')\n",
    "    return X\n",
    "\n",
    "def create_onehots(y_indices):\n",
    "    \"\"\"\n",
    "    create one hot vectors for the labels\n",
    "    \"\"\"\n",
    "    no_examples = len(y_indices)\n",
    "    no_classes = len(ingredients)\n",
    "    y = np.empty([no_examples, no_classes])\n",
    "    for i, hot_idx in enumerate(y_indices):\n",
    "        y_onehot = np.zeros(no_classes)\n",
    "        y_onehot[hot_idx] = 1.0\n",
    "        y[i] = y_onehot\n",
    "    return y\n",
    "    \n",
    "print(len(orig_recipes))\n",
    "filtered_recipes = filter_recipes(orig_recipes)\n",
    "print(len(filtered_recipes))\n",
    "\n",
    "recipes_indices = list(map(recipe_to_idx, tqdm(filtered_recipes)))\n",
    "\n",
    "y_indices = create_labels(recipes_indices)\n",
    "\n",
    "X = pad_X(recipes_indices)\n",
    "\n",
    "y = create_onehots(y_indices)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 34, 100)           182600    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3400)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 900)               3060900   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1826)              1645226   \n",
      "=================================================================\n",
      "Total params: 4,888,726\n",
      "Trainable params: 4,888,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 95196 samples, validate on 23800 samples\n",
      "Epoch 1/15\n",
      "95196/95196 [==============================] - 43s 447us/step - loss: 6.1033 - accuracy: 0.0519 - val_loss: 5.8767 - val_accuracy: 0.0561\n",
      "Epoch 2/15\n",
      "95196/95196 [==============================] - 52s 543us/step - loss: 5.6098 - accuracy: 0.0835 - val_loss: 5.6403 - val_accuracy: 0.0854\n",
      "Epoch 3/15\n",
      "95196/95196 [==============================] - 45s 470us/step - loss: 5.3254 - accuracy: 0.1145 - val_loss: 5.4313 - val_accuracy: 0.1062\n",
      "Epoch 4/15\n",
      "95196/95196 [==============================] - 44s 457us/step - loss: 5.0424 - accuracy: 0.1371 - val_loss: 5.2750 - val_accuracy: 0.1189\n",
      "Epoch 5/15\n",
      "95196/95196 [==============================] - 43s 451us/step - loss: 4.7590 - accuracy: 0.1591 - val_loss: 5.2148 - val_accuracy: 0.1271\n",
      "Epoch 6/15\n",
      "95196/95196 [==============================] - 41s 434us/step - loss: 4.4488 - accuracy: 0.1811 - val_loss: 5.2381 - val_accuracy: 0.1299\n",
      "Epoch 7/15\n",
      "95196/95196 [==============================] - 41s 429us/step - loss: 4.0983 - accuracy: 0.2110 - val_loss: 5.3325 - val_accuracy: 0.1296\n",
      "Epoch 8/15\n",
      "95196/95196 [==============================] - 43s 455us/step - loss: 3.7255 - accuracy: 0.2545 - val_loss: 5.4991 - val_accuracy: 0.1278\n",
      "Epoch 9/15\n",
      "95196/95196 [==============================] - 43s 450us/step - loss: 3.3525 - accuracy: 0.3081 - val_loss: 5.7031 - val_accuracy: 0.1250\n",
      "Epoch 10/15\n",
      "95196/95196 [==============================] - 42s 440us/step - loss: 2.9993 - accuracy: 0.3658 - val_loss: 5.9497 - val_accuracy: 0.1203\n",
      "Epoch 11/15\n",
      "95196/95196 [==============================] - 41s 428us/step - loss: 2.6722 - accuracy: 0.4258 - val_loss: 6.1940 - val_accuracy: 0.1160\n",
      "Epoch 12/15\n",
      "95196/95196 [==============================] - 41s 433us/step - loss: 2.3722 - accuracy: 0.4827 - val_loss: 6.4568 - val_accuracy: 0.1118\n",
      "Epoch 13/15\n",
      "95196/95196 [==============================] - 41s 426us/step - loss: 2.0961 - accuracy: 0.5399 - val_loss: 6.7629 - val_accuracy: 0.1149\n",
      "Epoch 14/15\n",
      "95196/95196 [==============================] - 41s 430us/step - loss: 1.8518 - accuracy: 0.5918 - val_loss: 7.0475 - val_accuracy: 0.1082\n",
      "Epoch 15/15\n",
      "95196/95196 [==============================] - 46s 486us/step - loss: 1.6266 - accuracy: 0.6430 - val_loss: 7.3651 - val_accuracy: 0.1061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a4188cc90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train Neural network\n",
    "no_classes = len(ingredients)\n",
    "input_length = X.shape[1]\n",
    "def get_compiled_model():\n",
    "    #model using embeddings\n",
    "    model = Sequential([\n",
    "            Embedding(input_dim=no_classes,\n",
    "                    output_dim=100, \n",
    "                    input_length=input_length),\n",
    "            Flatten(),\n",
    "            Dense(900, activation='relu'),\n",
    "            Dense(no_classes, activation='softmax')\n",
    "        ])\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_compiled_model()\n",
    "print(model.summary())\n",
    "model.fit(x=X, y=y, validation_split=0.2, epochs=15, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cheddar cheese', 0.08336744), ('onion', 0.074759744), ('salt and pepper', 0.059468783), ('salt', 0.05335347), ('white onion', 0.043249637), ('tomatoes', 0.039837014), ('blue cheese', 0.034071136), ('lemon juice', 0.027857946), ('green onions', 0.023794126), ('onion soup mix', 0.022429418)]\n"
     ]
    }
   ],
   "source": [
    "def predict_ingredients(recipe, k):\n",
    "    \"\"\"\n",
    "    returns k best suggestions in text\n",
    "    \"\"\"\n",
    "    \n",
    "    #convert word recipe to neural network input format\n",
    "    indices = recipe_to_idx(recipe)\n",
    "    \n",
    "    longest_recipe_size = max([len(recipe) for recipe in recipes_indices])\n",
    "    #pad sequences only take list as argument, thus we have to pick the first element whne we only \n",
    "    #want to predict one element\n",
    "    X = pad_sequences([indices], maxlen=longest_recipe_size, padding='post')\n",
    "    \n",
    "    #predict\n",
    "    suggested_ingr = model.predict(X)[0]\n",
    "    scores = np.sort(suggested_ingr)[::-1][:k]\n",
    "    \n",
    "    #get k \"best\" ingredients\n",
    "    k = min(k, len(suggested_ingr))\n",
    "    best_ingr_idx_list = suggested_ingr.argsort()[-k:][::-1]\n",
    "    \n",
    "    #convert neural network format to word recipe\n",
    "    return list(zip(idx_to_recipe(best_ingr_idx_list), scores))\n",
    "  \n",
    "#salad_recipe = ['lettuce', 'tomatoes', 'onion']\n",
    "meat_recipe = ['avocado', 'ground beef', 'sour cream']\n",
    "print(predict_ingredients(meat_recipe, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
